# =============================================================================
# .env – environment overrides for the Ollama / Open WebUI stack
# Copy this file to .env and fill in your values before running docker compose
# =============================================================================

# ── Storage paths ─────────────────────────────────────────────────────────────
# Point these at fast NVMe storage on your DGX Spark.
# The directories must exist before starting the stack (see README).
OLLAMA_DATA_PATH=/data/ollama
WEBUI_DATA_PATH=/data/open-webui

# ── Security ──────────────────────────────────────────────────────────────────
# Replace with a long random string, e.g.:  openssl rand -hex 32
WEBUI_SECRET_KEY=random_strong_secret_passphrase

# ── Ollama tuning ─────────────────────────────────────────────────────────────
# How many models can be resident in (V)RAM at once
OLLAMA_MAX_LOADED_MODELS=3
# Parallel inference requests per model
OLLAMA_NUM_PARALLEL=2
# Enable flash attention (faster, lower VRAM for supported models)
OLLAMA_FLASH_ATTENTION=1

# ── Open WebUI port ───────────────────────────────────────────────────────────
# Host port that maps to the WebUI's internal 8080
WEBUI_PORT=3000

# ── Ollama API port ───────────────────────────────────────────────────────────
OLLAMA_PORT=11434
