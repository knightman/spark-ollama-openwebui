# =============================================================================
# .env – environment overrides for the Ollama / Open WebUI stack
# Copy this file to .env and fill in your values before running docker compose
# =============================================================================

# ── Storage paths ─────────────────────────────────────────────────────────────
# Point these at fast NVMe storage on your DGX Spark.
# The directories must exist before starting the stack (see README).
OLLAMA_DATA_PATH=/data/ollama
WEBUI_DATA_PATH=/data/open-webui

# ── Security ──────────────────────────────────────────────────────────────────
# Replace with a long random string, e.g.:  openssl rand -hex 32
WEBUI_SECRET_KEY=random_strong_secret_passphrase
# API key and URL for dev-laptop tools (ingest.py, openwebui_mcp.py).
# Generate the API key in Open WebUI → Settings → Account → API Keys.
OPENWEBUI_API_KEY=
OPENWEBUI_URL=http://<your-spark-hostname>:3000

# ── Ollama tuning ─────────────────────────────────────────────────────────────
# How many models can be resident in (V)RAM at once
OLLAMA_MAX_LOADED_MODELS=3
# Parallel inference requests per model
OLLAMA_NUM_PARALLEL=2
# Enable flash attention (faster, lower VRAM for supported models)
OLLAMA_FLASH_ATTENTION=1

# ── Open WebUI port ───────────────────────────────────────────────────────────
# Host port that maps to the WebUI's internal 8080
WEBUI_PORT=3000

# ── Ollama API port ───────────────────────────────────────────────────────────
OLLAMA_PORT=11434

# ── Deploy (laptop → DGX Spark) ───────────────────────────────────────────────
# Used by deploy.sh to rsync this project to the Spark over SSH.
# Set these in your .env (never committed); deploy.sh reads them at runtime.
SPARK_SSH_USER=your_username
SPARK_SSH_HOST=your-spark-hostname
SPARK_DEPLOY_DIR=/home/your_username/ollama-stack
